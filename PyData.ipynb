{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How “good” is your model, and how can you make it better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What distinguishes “true artists” from “one-hit wonders” in machine learning is an understanding of how a model performs with respect to different data. This hands-on tutorial will show you how to use scikit-learn’s model evaluation functions to evaluate different models in terms of accuracy and generalisability, and search for optimal parameter configurations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.cross_validation as cv\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring and pre-processing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing you will need to do in order to work with the WDBC dataset is to read it in from the provided .csv data file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"wdbc.csv\", header=None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the data is converted into a numpy array, construct the data matrix X and the associated class vector y (target variable). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert to numpy array\n",
    "dataArray = np.array(data)\n",
    "\n",
    "# Cast the input data into type float\n",
    "X = dataArray[:,2:].astype(float)\n",
    "y = dataArray[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is always a good practice to check the dimensionality of the input data as soon as imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"X dimensions:\", X.shape\n",
    "print \"y dimensions:\", y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our current dataset, the y values (labels) are categorical (they can only take one of a discrete set of values) and have a non-numeric representation (\"M\" or \"B\"). This is problematic for scikit-learn algorithms, since they assume numerical values, so we need to map the text categories to numerical representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y)\n",
    "yTransformed = le.transform(y)\n",
    "# print yTransformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important thing to understand before applying any classification algorithms is how the output labels\n",
    "are distributed. Are they evenly distributed? Imbalances in distribution of labels can often lead to poor classification results for the minority class even if the classification results for the majority class\n",
    "are very good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yFreq = scipy.stats.itemfreq(y)\n",
    "print yFreq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is usually advisable to scare your data prior to fitting a classification model. The main advantage of scaling is to avoid attributes in greater numeric ranges dominating those in smaller numeric ranges. For the purposes of this case study, we are applying auto-scaling on the whole dataset (Auto-scaling: mean-centering performed per column; subsequently, scaling is applied by dividing the centered columns by their standard deviation). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xauto = preprocessing.StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can visualise the relationship between two variables (radius and perimeter of the tumour) using a simple scatter plot. To illustrate, let’s plot the first two variables against each other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(x = Xauto[yTransformed==0,0], y = Xauto[yTransformed==0,1], color = 'b', label='Benign')\n",
    "plt.scatter(x = Xauto[yTransformed==1,0], y = Xauto[yTransformed==1,1], color = 'r', label='Malignant')\n",
    "plt.xlabel(\"radius\")\n",
    "plt.ylabel(\"perimeter\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(Xauto[yTransformed==0,0], color='b', alpha=.5, label='Benign', bins=15)\n",
    "plt.hist(Xauto[yTransformed==1,0], color='r', alpha=.5, label='Malignant', bins=15)\n",
    "plt.xlabel(\"radius\")\n",
    "plt.ylabel(\"occurrences\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and testing a classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and testing a classification model on the same dataset is a methodological mistake: a model that would just repeat the labels of the samples that it has just seen would have a perfect score but would fail to predict anything useful on yet-unseen data (poor generalisation). <br/> \n",
    "\n",
    "To use different datasets for training and testing, we need to split the breast cancer dataset into two disjoint sets: train and test (**Holdout method**). <br/> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "XTrain, XTest, yTrain, yTest = cv.train_test_split(Xauto, yTransformed, test_size= 0.3, random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XTrain and yTrain are the two arrays you use to train your model. XTest and yTest are the two arrays that you use to evaluate your model. By default, scikit-learn splits the data so that 25% of it is used for testing, but you can also specify the proportion of data you want to use for training and testing (in this case, 30% is used for testing)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check the sizes of the different training and test sets by using the shape attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"XTrain dimensions:\", XTrain.shape\n",
    "print \"yTrain dimensions:\", yTrain.shape\n",
    "print \"XTest dimensions:\",  XTest.shape\n",
    "print \"yTest dimensions:\",  yTest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build KNN models using scikit-learn, you will be using the **KNeighborsClassifier** function, which allows you to set the value of K using the *n_neighbors* parameter. The optimal choice of the value K is highly data-dependent: in general a larger K suppresses the effects of noise, but makes the classification boundaries less distinct. <br/>\n",
    "\n",
    "### Uniform weights\n",
    "\n",
    "We are going to start by trying two predefined random values of K and compare their performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "knn3 = KNeighborsClassifier(n_neighbors=3)\n",
    "knn3.fit(XTrain, yTrain)\n",
    "yPredK3 = knn3.predict(XTest)\n",
    "\n",
    "print metrics.classification_report(yTest, yPredK3)\n",
    "print \"Overall Accuracy:\", round(metrics.accuracy_score(yTest, yPredK3), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "knn10 = KNeighborsClassifier(n_neighbors=10)\n",
    "knn10.fit(XTrain, yTrain)\n",
    "yPredK10 = knn10.predict(XTest)\n",
    "\n",
    "print metrics.classification_report(yTest, yPredK10)\n",
    "print \"Overall Accuracy:\", round(metrics.accuracy_score(yTest, yPredK10), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance weights\n",
    "\n",
    "Under some circumstances, it is better to give more importance (\"weight\" in computing terms) to nearer neighbours. When weights = \"distance\", weights are assigned to the training data points in a way that is proportional to the inverse of the distance from the query point. In other words, nearer neighbours contribute more to the fit. <br/>\n",
    "\n",
    "What if we use weights based on distance? Does it improve the overall performance? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "knnW3 = KNeighborsClassifier(n_neighbors=3, weights='distance')\n",
    "knnW3.fit(XTrain, yTrain)\n",
    "predictedW3 = knnW3.predict(XTest)\n",
    "\n",
    "print metrics.classification_report(yTest, predictedW3)\n",
    "print \"Overall Accuracy:\", round(metrics.accuracy_score(yTest, predictedW3), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plotvector(XTrain, yTrain, XTest, yTest, weights, upperLim = 310):\n",
    "    results = []\n",
    "    for n in range(1, upperLim, 4):\n",
    "        clf = KNeighborsClassifier(n_neighbors = n, weights = weights)\n",
    "        clf = clf.fit(XTrain, yTrain)\n",
    "        preds = clf.predict(XTest)\n",
    "        accuracy = clf.score(XTest, yTest)\n",
    "        results.append([n, accuracy])\n",
    "    results = np.array(results)\n",
    "    return(results)\n",
    "\n",
    "def plotaccuracy(XTrain, yTrain, XTest, yTest, upperLim):\n",
    "    pltvector1 = plotvector(XTrain, yTrain, XTest, yTest, weights = \"uniform\",  upperLim=upperLim)\n",
    "    pltvector2 = plotvector(XTrain, yTrain, XTest, yTest, weights = \"distance\", upperLim=upperLim)\n",
    "    line1 = plt.plot(pltvector1[:,0], pltvector1[:,1], label = \"uniform\",  color='blue')\n",
    "    line2 = plt.plot(pltvector2[:,0], pltvector2[:,1], label = \"distance\", color='red')\n",
    "    plt.legend(loc=3)\n",
    "    plt.ylim(0.85, 1)\n",
    "    plt.title('Accuracy with Increasing K')\n",
    "    plt.xlabel('Number of K nearest neighbors')\n",
    "    plt.ylabel('Classifiction Accuracy')\n",
    "    plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function plots the accuracies of applying the KNN algorithms with different k values for both uniform and distance weights up to a k value of 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 6))\n",
    "plotaccuracy(XTrain, yTrain, XTest, yTest, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning KNN parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sklearn library has a grid search function, GridSearchCV, that allows us to search for the optimum\n",
    "combination of parameters by evaluating models trained with a particular algorithm with all\n",
    "parameter combinations. You can use this function to search for a parametisation of the KNN algorithm\n",
    "that gives a more optimal model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We want to use odd numbers of k to avoid ties\n",
    "\n",
    "n_neighbors = np.arange(1, 50, 2)\n",
    "weights     = ['uniform','distance']\n",
    "\n",
    "# GridSearchCV accepts parameter values  only as a dictionary\n",
    "\n",
    "parameters = [{'n_neighbors': n_neighbors, 'weights': weights}]\n",
    "grid = GridSearchCV(KNeighborsClassifier(), parameters, cv= 10)\n",
    "grid.fit(XTrain, yTrain)\n",
    "\n",
    "print \"The best parameters are: n_neighbors=\", grid.best_params_['n_neighbors'],\"and weight=\",grid.best_params_['weights']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score_dict = grid.grid_scores_\n",
    "scores = [x[1] for x in score_dict]\n",
    "scores = np.array(scores).reshape(len(n_neighbors), len(weights))\n",
    "scores = np.transpose(scores)\n",
    "\n",
    "# Make a heatmap with the performance\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(scores, interpolation='nearest', origin='higher', cmap=plt.cm.get_cmap('jet_r'))\n",
    "\n",
    "plt.colorbar()\n",
    "plt.xticks(np.arange(len(n_neighbors)), n_neighbors)\n",
    "plt.yticks(np.arange(len(weights)), weights)\n",
    "plt.xlabel('Number of K nearest neighbors')\n",
    "plt.ylabel('Weights')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When evaluating the resulting model it is important to do it on held-out samples that were not seen during the grid search process (XTest). <br/> So, we are testing our independent XTest dataset using the optimised model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=grid.best_params_['n_neighbors'], weights = grid.best_params_['weights'])\n",
    "knn.fit(XTrain, yTrain)\n",
    "yPredKnn = knn3.predict(XTest)\n",
    "\n",
    "print metrics.classification_report(yTest, yPredKnn)\n",
    "print \"Overall Accuracy:\", round(metrics.accuracy_score(yTest, yPredKnn), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "from scipy.stats.distributions import randint\n",
    "param_dist = {'n_neighbors': randint(1,200)}\n",
    "random_search = RandomizedSearchCV(KNeighborsClassifier(), param_distributions=param_dist, n_iter=20)\n",
    "random_search.fit(XTrain, yTrain)\n",
    "\n",
    "print \"The best parameters are: n_neighbors=\", random_search.best_params_['n_neighbors']\n",
    "\n",
    "neig = [score_tuple[0]['n_neighbors'] for score_tuple in random_search.grid_scores_]\n",
    "res = [score_tuple[1] for score_tuple in random_search.grid_scores_]\n",
    "plt.scatter(neig, res)\n",
    "plt.xlabel('n_neighbors')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest (RF)\n",
    "\n",
    "Random forests aggregates a group of decision trees into an ensembles. It adds randomness in 2 ways, one is by sampling with replacement(bootstrap sampling) from the training data and then fitting a tree for each of these samples. Then splitting on a feature in the decision tree, random forest considers random subset of variables to split on. <br/>\n",
    "\n",
    "One of the most important tuning parameters in building a random forest is the number of trees to construct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_jobs=2)\n",
    "clf.fit(XTrain, yTrain)\n",
    "predRF = clf.predict(XTest)\n",
    "\n",
    "print metrics.classification_report(yTest, predRF)\n",
    "print \"Overall Accuracy:\", round(metrics.accuracy_score(yTest, predRF),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning RF parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main parameters to adjust when using these methods is n_estimators and max_features. The former is the number of trees in the forest. The larger the better, but also the longer it will take to compute. In addition, note that results will stop getting significantly better beyond a critical number of trees. The latter is the size of the random subsets of features to consider when splitting a node. The lower the greater the reduction of variance, but also the greater the increase in bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines (SVMs)\n",
    "\n",
    "SVMs attempt to build a decision boundary that accurately separates the samples of different classes by *maximizing* the margin between them.\n",
    "\n",
    "### Linear SVMs\n",
    "\n",
    "The parameter C, common to all SVM kernels, trades off misclassification of training examples against simplicity of the decision surface. A low C makes the decision surface smooth, while a high C aims at classifying all training examples correctly. \n",
    "\n",
    "In this example, we will use linear SVMs with the default value for C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Default C parameter\n",
    "linearSVM = SVC(kernel='linear')\n",
    "linearSVM.fit(XTrain, yTrain)\n",
    "yPredLinear = linearSVM.predict(XTest)\n",
    "\n",
    "print metrics.classification_report(yTest, yPredLinear)\n",
    "print \"Overall Accuracy:\", round(metrics.accuracy_score(yTest, yPredLinear),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-linear SVMs\n",
    "\n",
    "In addition to C, which is common for all types of SVM, the gamma parameter defines the nonlinearity of the bounaries. The larger the gamma is, the more nonlinear the boundaries surrounding individual samples. <br/> In this example, we will use non-linear SVMs with the default values for C and gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Default C and gamma parameters\n",
    "rbfSVM = SVC(kernel='rbf', C=1.0, gamma=0.0)\n",
    "rbfSVM.fit(XTrain, yTrain)\n",
    "yPredRBF = rbfSVM.predict(XTest)\n",
    "\n",
    "print metrics.classification_report(yTest, yPredRBF)\n",
    "print \"Overall Accuracy:\", round(metrics.accuracy_score(yTest, yPredRBF),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning\n",
    "\n",
    "Proper choice of C and gamma is critical for the performance of SVMs. Optimisation (tuning) of the hyperparameters can be achieved by applying a coarse tuning (often followed by a finer-tuning in the \"neighborhood\" of good parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Range for gamma and Cost hyperparameters\n",
    "g_range = 2. ** np.arange(-15, 5, step=2)\n",
    "C_range = 2. ** np.arange(-5, 15, step=2)\n",
    "\n",
    "grid = [{'gamma': g_range, 'C': C_range}]\n",
    "\n",
    "gridcv = GridSearchCV(SVC(), param_grid=grid, cv= cv.KFold(n=XTrain.shape[0], n_folds=5))\n",
    "gridcv.fit(XTrain, yTrain)\n",
    "\n",
    "bestG = np.log2(gridcv.best_params_['gamma']);\n",
    "bestC = np.log2(gridcv.best_params_['C']);\n",
    "\n",
    "print \"The best parameters are: gamma=\", bestG, \" and Cost=\", bestC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the results of the grid search using a heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot the scores of the grid\n",
    "# grid_scores_ contains parameter settings and scores\n",
    "score_dict = gridcv.grid_scores_\n",
    "\n",
    "# We extract just the scores\n",
    "scores = [x[1] for x in score_dict]\n",
    "scores = np.array(scores).reshape(len(C_range), len(g_range))\n",
    "\n",
    "# Make a heatmap with the performance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.subplots_adjust(left=0.15, right=0.95, bottom=0.15, top=0.95)\n",
    "plt.imshow(scores, interpolation='nearest', origin='higher', cmap=plt.cm.get_cmap('jet_r'))\n",
    "plt.xlabel('gamma (log2)')\n",
    "plt.ylabel('Cost (log2)')\n",
    "plt.colorbar()\n",
    "plt.xticks(np.arange(len(g_range)), np.log2(g_range))\n",
    "plt.yticks(np.arange(len(C_range)), np.log2(C_range))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, testing with the optimised model (best hyperparameters):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rbfSVM = SVC(kernel='rbf', C=gridcv.best_params_['C'], gamma=gridcv.best_params_['gamma'])\n",
    "rbfSVM.fit(XTrain, yTrain)\n",
    "\n",
    "predictions = rbfSVM.predict(XTest) \n",
    "\n",
    "print metrics.classification_report(yTest, predictions)\n",
    "print \"Overall Accuracy:\", round(metrics.accuracy_score(yTest, predictions),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "l_regression = LogisticRegression()\n",
    "l_regression.fit(XTrain, yTrain)\n",
    "net_prediction = l_regression.predict(XTest)\n",
    "\n",
    "print metrics.classification_report(yTest, net_prediction)\n",
    "print \"Overall Accuracy:\", round(metrics.accuracy_score(yTest, net_prediction),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Range for gamma and Cost hyperparameters\n",
    "pen = ['l1','l2']\n",
    "C_range = 2. ** np.arange(-5, 15, step=2)\n",
    "\n",
    "grid = [{'C': C_range, 'penalty': pen}]\n",
    "\n",
    "gridcv = GridSearchCV(LogisticRegression(), param_grid=grid, cv= cv.KFold(n=XTrain.shape[0], n_folds=5))\n",
    "gridcv.fit(XTrain, yTrain)\n",
    "\n",
    "best_c = gridcv.best_params_['C']\n",
    "best_penalty = gridcv.best_params_['penalty']\n",
    "\n",
    "print \"The best parameters are: cost=\", best_c, \" and penalty=\", best_penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from multilayer_perceptron import multilayer_perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nnet = multilayer_perceptron.MultilayerPerceptronClassifier(activation='logistic',\n",
    "                                                            hidden_layer_sizes=(2), learning_rate_init=.5)\n",
    "nnet.fit(XTrain, yTrain)\n",
    "net_prediction = nnet.predict(XTest)\n",
    "\n",
    "print metrics.classification_report(yTest, net_prediction)\n",
    "print \"Overall Accuracy:\", round(metrics.accuracy_score(yTest, net_prediction),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Range for gamma and Cost hyperparameters\n",
    "layer_size_range = [(3,2),(10,10),(2,2,2),10,5] # different networks shapes\n",
    "learning_rate_range = np.linspace(.1,1,3)\n",
    "\n",
    "grid = [{'hidden_layer_sizes': layer_size_range, 'learning_rate_init': learning_rate_range}]\n",
    "\n",
    "gridcv = GridSearchCV(multilayer_perceptron.MultilayerPerceptronClassifier(), \n",
    "                      param_grid=grid, cv= cv.KFold(n=XTrain.shape[0], n_folds=5))\n",
    "gridcv.fit(XTrain, yTrain)\n",
    "\n",
    "best_size = gridcv.best_params_['hidden_layer_sizes']\n",
    "best_best_lr = gridcv.best_params_['learning_rate_init']\n",
    "\n",
    "print \"The best parameters are: hidden_layer_sizes=\", best_size, \" and learning_rate_init=\", best_best_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nnet = multilayer_perceptron.MultilayerPerceptronClassifier(hidden_layer_sizes=(2, 2, 2), learning_rate_init=.1)\n",
    "nnet.fit(XTrain, yTrain)\n",
    "net_prediction = nnet.predict(XTest)\n",
    "\n",
    "print metrics.classification_report(yTest, net_prediction)\n",
    "print \"Overall Accuracy:\", round(metrics.accuracy_score(yTest, net_prediction),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv.cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
